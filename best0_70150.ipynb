{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d40f19b-9a2f-4f86-adc7-500efa311abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, StratifiedKFold,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303707b6-e226-415b-898f-2227461dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_diab.csv')\n",
    "test_df = pd.read_csv('test_diab.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec684c07-9ef6-4436-9057-59a97aa496d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"diagnosed_diabetes\"\n",
    "X = train_df.drop(columns=[TARGET])\n",
    "y = train_df[TARGET]\n",
    "\n",
    "test_ids = test_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a2cf7c-cd05-48df-8a9e-d17c0802cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "\n",
    "X[cat_cols] = enc.fit_transform(X[cat_cols])\n",
    "test_df[cat_cols] = enc.transform(test_df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343ee339-d438-4a8a-b77b-109b35f6de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "KF = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "oof_cat = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "\n",
    "pred_lgb = np.zeros(len(test_df))\n",
    "pred_cat = np.zeros(len(test_df))\n",
    "pred_xgb = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd8b2aa-4f1e-4e93-a096-da2288356f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1 / 5 =====\n",
      "[LightGBM] [Info] Number of positive: 349045, number of negative: 210955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "===== FOLD 2 / 5 =====\n",
      "[LightGBM] [Info] Number of positive: 349045, number of negative: 210955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1896\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "===== FOLD 3 / 5 =====\n",
      "[LightGBM] [Info] Number of positive: 349046, number of negative: 210954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1898\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "\n",
      "===== FOLD 4 / 5 =====\n",
      "[LightGBM] [Info] Number of positive: 349046, number of negative: 210954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "\n",
      "===== FOLD 5 / 5 =====\n",
      "[LightGBM] [Info] Number of positive: 349046, number of negative: 210954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 560000, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_idx, val_idx) in enumerate(KF.split(X, y)):\n",
    "    print(f\"\\n===== FOLD {fold+1} / 5 =====\")\n",
    "\n",
    "    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    # LightGBM\n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=64,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "    lgb.fit(X_train, y_train)\n",
    "\n",
    "    oof_lgb[val_idx] = lgb.predict_proba(X_valid)[:, 1]\n",
    "    pred_lgb += lgb.predict_proba(test_df)[:, 1] / KF.n_splits\n",
    "\n",
    "    # CatBoost\n",
    "    cat = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    depth=6,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=6,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=42,\n",
    "    verbose=False)\n",
    "    cat.fit(X_train, y_train)\n",
    "    oof_cat[val_idx] = cat.predict_proba(X_valid)[:, 1]\n",
    "    pred_cat += cat.predict_proba(test_df)[:, 1] / KF.n_splits\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"auc\",\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    oof_xgb[val_idx] = xgb.predict_proba(X_valid)[:, 1]\n",
    "    pred_xgb += xgb.predict_proba(test_df)[:, 1] / KF.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5c2197b-0a18-40a0-ada6-6456a0528cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_blend = 0.4 * oof_lgb + 0.35 * oof_cat + 0.25 * oof_xgb\n",
    "pred_blend = 0.4 * pred_lgb + 0.35 * pred_cat + 0.25 * pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "746a2d16-f9aa-492e-b396-85139d843d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM ROC: 0.7271809204666989\n",
      "CatBoost ROC: 0.725814100943837\n",
      "XGBoost ROC: 0.7264871649112523\n",
      "Blended ROC: 0.7273611194537963\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLightGBM ROC:\", roc_auc_score(y, oof_lgb))\n",
    "print(\"CatBoost ROC:\", roc_auc_score(y, oof_cat))\n",
    "print(\"XGBoost ROC:\", roc_auc_score(y, oof_xgb))\n",
    "print(\"Blended ROC:\", roc_auc_score(y, oof_blend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec5d4f30-0fe0-43c7-b1e4-e9f6564d10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Stacked ROC: 0.7274533389878863\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "\n",
    "stack_train = np.vstack([oof_lgb, oof_cat, oof_xgb]).T\n",
    "stack_test  = np.vstack([pred_lgb, pred_cat, pred_xgb]).T\n",
    "\n",
    "lvl2 = LogisticRegression(max_iter=2000)\n",
    "lvl2.fit(stack_train, y)\n",
    "\n",
    "pred_final = lvl2.predict_proba(stack_test)[:, 1]\n",
    "\n",
    "print(\"\\nFinal Stacked ROC:\",\n",
    "      roc_auc_score(y, lvl2.predict_proba(stack_train)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36fb5b9-0354-4320-91a9-c7bcb1289602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"diagnosed_diabetes\": pred_final\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission3013251626.csv\", index=False)\n",
    "print(\"submission.csv saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
